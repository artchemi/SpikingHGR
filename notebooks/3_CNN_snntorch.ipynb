{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce2d0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import snntorch as snn \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from config import *\n",
    "from src.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e049d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e83cfe",
   "metadata": {},
   "source": [
    "# Convolutional SNN\n",
    "\n",
    "Краткий туториал по устройству свертки в импульснах нейронных сетях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637eafe7",
   "metadata": {},
   "source": [
    "## Импорт датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc1e6b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "emg, label = folder_extract('../'+FOLDER_PATH, exercises=EXERCISES, myo_pref=MYO_PREF)\n",
    "all_g = gestures(emg, label, targets=GESTURE_INDEXES_MAIN)\n",
    "\n",
    "train_g, test_g = train_test_split(all_g, split_size=0.2, rand_seed=GLOBAL_SEED)\n",
    "\n",
    "X_train_raw, y_train = apply_window(train_g, window=WINDOW_SIZE, step=STEP_SIZE)\n",
    "X_test_raw,  y_test  = apply_window(test_g,  window=WINDOW_SIZE, step=STEP_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a334a3",
   "metadata": {},
   "source": [
    "## Стандартизация и подготовка к размерности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f955c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = X_train_raw.mean(axis=(0, 2))       # (channels,)\n",
    "stds  = X_train_raw.std(axis=(0, 2)) + 1e-8\n",
    "\n",
    "def standardize(X):\n",
    "    return (X - means[None,:,None]) / stds[None,:,None]\n",
    "\n",
    "X_train = standardize(X_train_raw)\n",
    "X_test = standardize(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35600c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(X):\n",
    "    Xt = np.transpose(X, (0, 2, 1))   # [N, window, channels]\n",
    "    sel = Xt[..., CHANNELS]           # отбор каналов\n",
    "    return sel[..., np.newaxis].astype(np.float32)\n",
    "\n",
    "X_train = prepare(X_train)  # Готовые данные\n",
    "X_test = prepare(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39ba23a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32).permute(0, 3, 2, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).permute(0, 3, 2, 1)\n",
    "\n",
    "train_dataset = SpikingEMGDataset(X=X_train, y=y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "test_dataset = SpikingEMGDataset(X=X_test, y=y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a4669bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32941, 1, 8, 52])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape    # (кол-во окон, 1, размерность окна, количество каналов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f43d80",
   "metadata": {},
   "source": [
    "## Определение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3426bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_grad = snn.surrogate.fast_sigmoid(slope=25)\n",
    "beta = 0.5\n",
    "num_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86f37f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = (1, 3)\n",
    "pool_size = (1, 2)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=kernel_size, padding=\"same\")\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.mp1 = nn.MaxPool2d(pool_size)\n",
    "        self.conv2 = nn.Conv2d(8, 24, kernel_size=kernel_size, padding=\"same\")\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "        self.mp2 = nn.MaxPool2d(pool_size)\n",
    "        self.fc = nn.Linear(2496, 9)\n",
    "        self.lif3 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden states at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "        \n",
    "        # Record the final layer\n",
    "        spk3_rec = []\n",
    "        mem3_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            cur1 = self.conv1(x)\n",
    "            spk1, mem1 = self.lif1(self.mp1(cur1), mem1)\n",
    "            cur2 = self.conv2(spk1)\n",
    "            spk2, mem2 = self.lif2(self.mp2(cur2), mem2)\n",
    "            cur3 = self.fc(spk2.flatten(1))\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "\n",
    "            spk3_rec.append(spk3)\n",
    "            mem3_rec.append(mem3)\n",
    "\n",
    "        return torch.stack(spk3_rec, dim=0), torch.stack(mem3_rec, dim=0)\n",
    "        \n",
    "# Load the network onto CUDA if available\n",
    "device = 'cuda'\n",
    "dtype = torch.float\n",
    "convnet = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c620a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/257 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LBFGS.step() missing 1 required positional argument: 'closure'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     23\u001b[0m loss_val\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 24\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# train accuracy\u001b[39;00m\n\u001b[1;32m     27\u001b[0m preds \u001b[38;5;241m=\u001b[39m summed\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/1_CNN_gestures/SpikingHGR/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:516\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    512\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    513\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m             )\n\u001b[0;32m--> 516\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    519\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/1_CNN_gestures/SpikingHGR/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: LBFGS.step() missing 1 required positional argument: 'closure'"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(convnet.parameters(), lr=1e-4, betas=(0.9, 0.999), weight_decay=1e-4)    # (0.9, 0.999)\n",
    "# optimizer = torch.optim.LBFGS(convnet.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 100\n",
    "loss_hist = []\n",
    "acc_hist = []\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    # ——— TRAINING LOOP ———\n",
    "    convnet.train()\n",
    "    for data, targets in tqdm(train_loader):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "        # forward + loss\n",
    "        spk_rec      = convnet(data)[0]                # [T, batch, n_classes]\n",
    "        summed       = spk_rec.sum(dim=0)              # [batch, n_classes]\n",
    "        loss_val     = loss_fn(summed, targets)\n",
    "\n",
    "        # backward + update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # train accuracy\n",
    "        preds = summed.argmax(dim=1)\n",
    "        acc   = (preds==targets).float().mean().item()\n",
    "\n",
    "        # log histories\n",
    "        loss_hist.append(loss_val.item())\n",
    "        acc_hist.append(acc)\n",
    "\n",
    "        # if counter % 10 == 0:\n",
    "        #     print(f\"Iter {counter:4d} | Train Loss: {loss_val:.4f} | Train Acc: {acc:.4f}\")\n",
    "        counter += 1\n",
    "\n",
    "    # ——— VALIDATION LOOP ———\n",
    "    convnet.eval()\n",
    "    test_loss = 0.0\n",
    "    correct   = 0\n",
    "    total     = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_main = []\n",
    "        target_main = []\n",
    "        for data, targets in test_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "            spk_rec = convnet(data)[0]\n",
    "            summed  = spk_rec.sum(dim=0)\n",
    "            loss_t  = loss_fn(summed, targets)\n",
    "\n",
    "            test_loss += loss_t.item() * data.size(0)\n",
    "            preds     = summed.argmax(dim=1)\n",
    "            correct  += (preds == targets).sum().item()\n",
    "            total    += targets.size(0)\n",
    "\n",
    "            target_main.extend(targets.cpu())\n",
    "            output_main.extend(preds.cpu())\n",
    "\n",
    "    # усредняем по всему test_loader\n",
    "    avg_test_loss = test_loss / total\n",
    "    test_acc      = correct / total\n",
    "\n",
    "    f1_test = f1_score(target_main, output_main, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"Epoch {epoch:2d} | Test Loss: {avg_test_loss:.4f} | Test Acc: {test_acc:.4f} | Test F1: {f1_test:.4f}\")\n",
    "\n",
    "    # при необходимости досрочно остановить после 100 итераций train\n",
    "    # if counter >= 100:\n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8d9840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet Accuracy: 0.907254159450531\n"
     ]
    }
   ],
   "source": [
    "def measure_accuracy(model, dataloader):\n",
    "  with torch.no_grad():\n",
    "    model.eval()\n",
    "    running_length = 0\n",
    "    running_accuracy = 0\n",
    "\n",
    "    for data, targets in iter(dataloader):\n",
    "      data = data.to(device)\n",
    "      targets = targets.to(device)\n",
    "\n",
    "      # forward-pass\n",
    "      spk_rec, _ = model(data)\n",
    "      spike_count = spk_rec.sum(0)\n",
    "      _, max_spike = spike_count.max(1)\n",
    "\n",
    "      # correct classes for one batch\n",
    "      num_correct = (max_spike == targets).sum()\n",
    "\n",
    "      # total accuracy\n",
    "      running_length += len(targets)\n",
    "      running_accuracy += num_correct\n",
    "    \n",
    "    accuracy = (running_accuracy / running_length)\n",
    "\n",
    "    return accuracy.item()\n",
    "\n",
    "print(f\"ConvNet Accuracy: {measure_accuracy(convnet, test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c99eac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
